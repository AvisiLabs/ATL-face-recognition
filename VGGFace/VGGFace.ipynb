{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Copyright notice from VGG-Face\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2017 kbehouse\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "daf423e4-54ec-488c-9932-e3c87402e407",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d257b37-aeff-40fb-906a-663fde21bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir\n",
    "from random import choice\n",
    "\n",
    "#Architecture and pretrained weights from https://github.com/serengil/tensorflow-101/blob/master/python/vgg-face.ipynb\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from matplotlib import pyplot\n",
    "from numpy import asarray, savez_compressed, load, expand_dims\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cf3469-1e81-4bc6-b99e-5ad474502ceb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Extract faces from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f4a99-9dfc-4c0d-a98d-ece45dc8dfa8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "FILENAME_DATASET = 'labs-dataset.npz'\n",
    "FILENAME_FEATURE_VECTORS = 'labs-embeddings.npz'\n",
    "\n",
    "\n",
    "def extract_face(filename, required_size=(224, 224)):\n",
    "    img = Image.open(filename)\n",
    "    img = img.resize(required_size)\n",
    "    img_array = asarray(img)\n",
    "    return img_array\n",
    "\n",
    "\n",
    "# load images and extract faces for all images in a directory\n",
    "def load_faces(directory):\n",
    "    face_list = list()\n",
    "    for filename in listdir(directory):\n",
    "        if filename == '.DS_Store':\n",
    "            continue\n",
    "        path = directory + filename\n",
    "        face = extract_face(path)\n",
    "        face_list.append(face)\n",
    "    return face_list\n",
    "\n",
    "\n",
    "# load a dataset that contains one subdir for each class that in turn contains images\n",
    "def load_dataset(directory):\n",
    "    X, y = list(), list()\n",
    "    # enumerate folders, on per class\n",
    "    for subdir in listdir(directory):\n",
    "        path = directory + subdir + '/'\n",
    "        if not isdir(path):\n",
    "            continue\n",
    "        # load all faces in the subdirectory\n",
    "        faces = load_faces(path)\n",
    "        labels = [subdir for _ in range(len(faces))]\n",
    "        print('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "    return asarray(X), asarray(y)\n",
    "\n",
    "\n",
    "# load train dataset\n",
    "train_X, train_y = load_dataset('../faces/train/')\n",
    "# load test dataset\n",
    "test_X, test_y = load_dataset('../faces/val/')\n",
    "# save arrays to one file in compressed format\n",
    "savez_compressed(FILENAME_DATASET, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265063a1-350b-4490-ba19-cef366bc7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the weights and put them in the same folder as this code from: https://drive.google.com/file/d/1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo/view?usp=sharing\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=(224, 224, 3)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "model.load_weights('vgg_face_weights.h5')\n",
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e52ee3-394e-424f-9a2f-e654aa7972df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badc5bb4-5778-4c51-98af-6118409b162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, face_pixels):\n",
    "    # scale pixel values\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    # standardize pixel values across channels (global)\n",
    "    mean, std = face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    # transform face into one sample\n",
    "    sample = expand_dims(face_pixels, axis=0)\n",
    "    # make prediction to get embedding\n",
    "    yhat = model.predict(sample)\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d931bbb9-1721-46e9-9dab-07212507ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_compressed_dataset(path):\n",
    "    # Load a dataset with np.load with pickle enabled and then put the normal np.load back\n",
    "    # save np.load\n",
    "    np_load_old = np.load\n",
    "\n",
    "    # modify the default parameters of np.load\n",
    "    np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "    data = np.load(path)\n",
    "    # putback the old load functionality\n",
    "    load = np_load_old\n",
    "    np.load = np_load_old\n",
    "    return data\n",
    "\n",
    "\n",
    "data = load_compressed_dataset(FILENAME_DATASET)\n",
    "\n",
    "train_X, train_y, test_X, test_y = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "print('Loaded: ', train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "\n",
    "def get_embeddingsarray(dataset):\n",
    "    new_dataset = list()\n",
    "    for face_pixels in dataset:\n",
    "        embedding = get_embedding(model, face_pixels)\n",
    "        new_dataset.append(embedding)\n",
    "    return asarray(new_dataset)\n",
    "\n",
    "\n",
    "# convert each face in train set to an embedding\n",
    "new_train_X = get_embeddingsarray(train_X)\n",
    "# do the same for the test set\n",
    "new_test_X = get_embeddingsarray(test_X)\n",
    "# save arrays to one file in compressed format\n",
    "savez_compressed(FILENAME_FEATURE_VECTORS, new_train_X, train_y, new_test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f9dd5b-22d5-46ff-99bf-10c69e105100",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b5245-662d-4809-987b-7d67208af961",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load faces\n",
    "data = load(FILENAME_DATASET)\n",
    "test_X_faces = data['arr_2']\n",
    "# load face embeddings\n",
    "data = load(FILENAME_FEATURE_VECTORS)\n",
    "train_X, train_y, test_X, test_y = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "# normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "train_X = in_encoder.transform(train_X)\n",
    "print(train_X.shape)\n",
    "test_X = in_encoder.transform(test_X)\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(train_y)\n",
    "train_y = out_encoder.transform(train_y)\n",
    "test_y = out_encoder.transform(test_y)\n",
    "# fit model\n",
    "model_svc = SVC(kernel='linear', probability=True, C=3)\n",
    "model_svc.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5472482b-9b9c-4f7b-ba9a-98cbbca1c43f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1421eb-f88e-4da8-8a43-9524c8295028",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "selection = choice([i for i in range(test_X.shape[0])])\n",
    "random_face_pixels = test_X_faces[selection]\n",
    "random_face_emb = test_X[selection]\n",
    "random_face_class = test_y[selection]\n",
    "random_face_name = out_encoder.inverse_transform([random_face_class])\n",
    "# prediction for the face\n",
    "samples = expand_dims(random_face_emb, axis=0)\n",
    "yhat_class = model_svc.predict(samples)\n",
    "yhat_prob = model_svc.predict_proba(samples)\n",
    "# get name\n",
    "class_probability = np.amax(yhat_prob)\n",
    "index = np.where(yhat_prob == class_probability)\n",
    "predict_names = out_encoder.classes_\n",
    "print('Predicted: %s (%.3f)' % (predict_names[index[1]], class_probability))\n",
    "print('Expected: %s' % random_face_name)\n",
    "# plot for fun\n",
    "pyplot.imshow(random_face_pixels)\n",
    "title = '%s (%.3f)' % (predict_names[index[1]], class_probability)\n",
    "pyplot.title(title)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef69f0d-ea10-4717-875c-d0b50f8d1b94",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Read an image and get a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5e18c-141b-4bb8-bfde-89fcc8367c9e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "modelFile = \"res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "configFile = \"deploy.prototxt.txt\"\n",
    "net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "imgLoc = '../banaan.png'\n",
    "img = cv2.imread(imgLoc)\n",
    "height, width = img.shape[:2]\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)),\n",
    "                             1.0, (300, 300), (104.0, 117.0, 123.0))\n",
    "net.setInput(blob)\n",
    "faces = net.forward()\n",
    "#OPENCV DNN\n",
    "for i in range(faces.shape[2]):\n",
    "    confidence = faces[0, 0, i, 2]\n",
    "    if confidence > 0.5:\n",
    "        box = faces[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "        faceimg = Image.fromarray(box)\n",
    "        (x, y, x1, y1) = box.astype(\"int\")\n",
    "\n",
    "img = Image.open(imgLoc)\n",
    "#img = img.crop((x , y, x1, y1))\n",
    "img = img.resize((224, 224))\n",
    "img = img.convert('RGB')\n",
    "pyplot.imshow(img)\n",
    "array = asarray(img)\n",
    "embed = get_embedding(model, array)\n",
    "embed = expand_dims(embed, axis=0)\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "train_X = in_encoder.transform(embed)\n",
    "yhat_class = model_svc.predict(train_X)\n",
    "yhat_prob = model_svc.predict_proba(train_X)\n",
    "print(yhat_prob)\n",
    "class_probability = np.amax(yhat_prob)\n",
    "index = np.where(yhat_prob == class_probability)\n",
    "predict_names = out_encoder.classes_\n",
    "print(predict_names)\n",
    "print('Predicted: %s (%.3f)' % (predict_names[index[1]], class_probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb3b2b9-f781-42f7-95cc-6c1ee842d953",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Setting up the Tensorboard projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803a6b9-9cc6-4ff7-bb91-315f259447d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tensorboard.plugins import projector\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fd837b-8a47-40a3-a06b-6096abc777f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_projector(\n",
    "        x,\n",
    "        feature_vector,\n",
    "        y,\n",
    "        class_names,\n",
    "        log_dir=\"logsVGG\",\n",
    "        meta_file=\"metadata.tsv\",\n",
    "):\n",
    "    assert x.ndim == 4  # (BATCH, H, W, C)\n",
    "\n",
    "    if os.path.isdir(log_dir):\n",
    "        shutil.rmtree(log_dir)\n",
    "\n",
    "    # Create a new clean fresh folder :)\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "    sprites_file = os.path.join(log_dir, \"sprites.png\")\n",
    "    sprite_x = x * 255\n",
    "    sprite = create_sprite(sprite_x)\n",
    "    img = Image.fromarray(sprite)\n",
    "    img.save(sprites_file)\n",
    "\n",
    "    # Generate label names\n",
    "    labels = []\n",
    "    for i in range(int(y.shape[0])):\n",
    "        labels.append([])\n",
    "        labels[i].append(class_names[y[i]])\n",
    "\n",
    "    with open(os.path.join(log_dir, meta_file), \"w\") as f:\n",
    "        for label in labels:\n",
    "            f.write(\"{}\\n\".format(label))\n",
    "\n",
    "    if feature_vector.ndim != 2:\n",
    "        print(\n",
    "            \"NOTE: Feature vector is not of form (BATCH, FEATURES)\"\n",
    "            \" reshaping to try and get it to this form!\"\n",
    "        )\n",
    "        feature_vector = tf.reshape(feature_vector, [feature_vector.shape[0], -1])\n",
    "    print(feature_vector.shape)\n",
    "\n",
    "    feature_vector = tf.Variable(feature_vector)\n",
    "    checkpoint = tf.train.Checkpoint(embedding=feature_vector)\n",
    "    checkpoint.save(os.path.join(log_dir, \"embeddings.ckpt\"))\n",
    "\n",
    "    # Set up config\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "    embedding.metadata_path = meta_file\n",
    "    embedding.sprite.image_path = \"sprites.png\"\n",
    "    embedding.sprite.single_image_dim.extend((x.shape[1], x.shape[2]))\n",
    "    projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b123bd-2948-4bd7-b98e-a21d11d288c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sprite(data):\n",
    "    \"\"\"Creates the sprite image along with any necessary padding\n",
    "\n",
    "    Args:\n",
    "      data: NxHxW[x3] tensor containing the images.\n",
    "\n",
    "    Returns:\n",
    "      data: Properly shaped HxWx3 image with any necessary padding.\n",
    "    \"\"\"\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[..., np.newaxis], (1, 1, 1, 3))\n",
    "    data = data.astype(np.float32)\n",
    "    min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1, 2, 3, 0) - min).transpose(3, 0, 1, 2)\n",
    "    max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1, 2, 3, 0) / max).transpose(3, 0, 1, 2)\n",
    "    data = 1 - data\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n",
    "               (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant',\n",
    "                  constant_values=0)\n",
    "    # Tile the individual thumbnails into an image.\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n",
    "                                                           + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16f1646-a20a-4465-8692-15a89f075069",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = load_dataset('../faces/train/')\n",
    "test_X, test_y = load_dataset('../faces/val/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d87650-3aba-4cf7-b43a-1ec37ae942d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = load(FILENAME_FEATURE_VECTORS)\n",
    "new_train_X, new_train_y, new_test_X, new_test_y = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n",
    "# normalize input vectors\n",
    "in_encoder = Normalizer(norm='l2')\n",
    "new_train_X = in_encoder.transform(new_train_X)\n",
    "new_test_X = in_encoder.transform(new_test_X)\n",
    "# label encode targets\n",
    "out_encoder = LabelEncoder()\n",
    "out_encoder.fit(train_y)\n",
    "new_train_y = out_encoder.transform(new_train_y)\n",
    "new_test_y = out_encoder.transform(new_test_y)\n",
    "X = np.concatenate((new_train_X, new_test_X), axis=0)\n",
    "y = np.concatenate((new_train_y, new_test_y), axis=0)\n",
    "new_X = []\n",
    "for i in X:\n",
    "    emb = np.zeros((1, 5))\n",
    "    i = expand_dims(i, axis=0)\n",
    "    emb[0, :] = model_svc.predict_proba(i)\n",
    "    new_X.append(emb)\n",
    "new_X = asarray(new_X)\n",
    "new_X = np.rollaxis(new_X, 1, 0)\n",
    "new_X = new_X[0, :, :]\n",
    "X = np.concatenate((train_X, test_X), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8386de19-4364-4e15-84b9-b219b754c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_to_projector(X, new_X, asarray(y), ['Albert', 'Eline', 'Erik', 'Kevin', 'Marcel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7de956-2015-4152-ba2b-cef88314432d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}