{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c4f2d-c12b-4608-ae72-d6f6db5e8438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image\n",
    "% matplotlib inline\n",
    "# Define some variables for later\n",
    "\n",
    "PATH = os.getcwd()\n",
    "LOG_DIR = PATH + '/logOld'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54ad7d8-ea80-49c9-88ff-091d2079eb01",
   "metadata": {},
   "source": [
    "# Import images and labels from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8693ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('AVL-Images.csv')  # reading the csv file\n",
    "print(labels.head())  # printing first five rows of the file\n",
    "\n",
    "train_image = []\n",
    "files = glob('../images/*.jpg')\n",
    "for file in files:\n",
    "    img = image.load_img(file, target_size=(256, 256, 3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img / 255\n",
    "    img = img[..., ::-1]\n",
    "    train_image.append(img)\n",
    "X = np.array(train_image)\n",
    "y = np.array(labels.loc[:, ['Albert', 'Eline', 'Erik', 'Kevin', 'Marcel']])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d871ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=30, test_size=0.1)\n",
    "\n",
    "#Exact size of train_X to fill with data to extract in the following for loop.\n",
    "fillable_X = np.zeros((264, 256, 256, 3), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a0971f-bcc3-4fb3-965f-2ff35ef3b247",
   "metadata": {},
   "source": [
    "# Generate data and apply modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e4086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_X = np.concatenate((train_X, fillable_X), axis=3)\n",
    "datagen = image.ImageDataGenerator(featurewise_center=True, rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "datagen.fit(datagen_X)\n",
    "X_batches = datagen_X\n",
    "y_batches = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb503cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "\n",
    "for e in range(epochs):\n",
    "    print('Epoch', e)\n",
    "    batches = 0\n",
    "    batch_size = 6\n",
    "    for X_batch, y_batch in datagen.flow(datagen_X, train_y, batch_size=batch_size):\n",
    "        X_batches = np.concatenate((X_batches, X_batch), axis=0)\n",
    "        y_batches = np.concatenate((y_batches, y_batch), axis=0)\n",
    "        batches += 1\n",
    "        if batches >= len(datagen_X) / batch_size:\n",
    "            break\n",
    "\n",
    "#Imagegenerator adds another dimension that we don't need so we remove it.\n",
    "train_X_new = X_batches[:, :, :, :3]\n",
    "train_X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0983c22-36bd-4ffb-9bdb-19718c127636",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modification = image.save_img(\"modification1.jpg\", train_X_new[458][..., ::-1])\n",
    "plt.imshow(train_X_new[458][..., ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e08816",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=(5), activation=\"relu\", input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu', name='intermediate'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535b86a8-6c3b-4910-8903-86a9e74ba735",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ad0dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=2, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c51e0-ed16-40ac-b2cd-e974d06829b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1, write_images=True)\n",
    "hist = model.fit(train_X, train_y, shuffle=True, epochs=100, validation_data=(test_X, test_y), callbacks=[tensorboard_callback, earlystopping],\n",
    "                 class_weight={0: 0.5653846154, 1: 0.5495327103, 2: 0.4983050847, 3: 0.5345454545, 4: 0.6461538462})\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113c352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c374bc1-a9bc-4b67-9946-493fa4e2f306",
   "metadata": {},
   "source": [
    "# Predict classes for an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcce1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img('../erik.jpg', target_size=(256, 256, 3))\n",
    "img = image.img_to_array(img)\n",
    "img = img / 255\n",
    "classes = np.array(labels.columns[2:])\n",
    "proba = model.predict(img.reshape(1, 256, 256, 3))\n",
    "top_3 = np.argsort(proba[0])[:-4:-1]\n",
    "for i in range(3):\n",
    "    print(\"{}\".format(classes[top_3[i]]) + \" ({:.3})\".format(proba[0][top_3[i]]))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85100d64",
   "metadata": {},
   "source": [
    "# Featurevector file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9823e76f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def img_features(image_file_name):\n",
    "    image_features = np.zeros((1, 5))\n",
    "    im = image.load_img(image_file_name, target_size=(256, 256, 3))\n",
    "    im = image.img_to_array(im)\n",
    "    im = im / 255\n",
    "    #last layer of model\n",
    "    image_features[0, :] = model.predict(im.reshape(1, 256, 256, 3))[0]\n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a0f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "data_path = '../images'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "image_features_list = []\n",
    "\n",
    "for img in sorted(data_dir_list):\n",
    "    if (img == '.DS_Store'):\n",
    "        continue\n",
    "    image_features = img_features(data_path + '/' + img)\n",
    "    image_features_list.append(image_features)\n",
    "\n",
    "image_features_arr = np.asarray(image_features_list)\n",
    "image_features_arr = np.rollaxis(image_features_arr, 1, 0)\n",
    "image_features_arr = image_features_arr[0, :, :]\n",
    "\n",
    "np.savetxt('feature_vectors_400_samples.txt', image_features_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b544b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors = np.loadtxt('feature_vectors_400_samples.txt')\n",
    "features = tf.Variable(feature_vectors, name='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58505517-33b2-4cba-8e8f-f216e94bb9a4",
   "metadata": {},
   "source": [
    "# Setting up the Tensorboard projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ffc641",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "from tensorboard.plugins import projector\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de47cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_projector(\n",
    "        x,\n",
    "        feature_vector,\n",
    "        y,\n",
    "        class_names,\n",
    "        log_dir=\"logold\",\n",
    "        meta_file=\"metadata.tsv\",\n",
    "):\n",
    "    assert x.ndim == 4  # (BATCH, H, W, C)\n",
    "\n",
    "    if os.path.isdir(log_dir):\n",
    "        shutil.rmtree(log_dir)\n",
    "\n",
    "    # Create a new clean fresh folder :)\n",
    "    os.mkdir(log_dir)\n",
    "\n",
    "    SPRITES_FILE = os.path.join(log_dir, \"sprites.png\")\n",
    "    sprite_x = x * 255\n",
    "    sprite = create_sprite(sprite_x)\n",
    "    cv2.imwrite(SPRITES_FILE, sprite)\n",
    "\n",
    "    # Generate label names\n",
    "    labels = []\n",
    "    for i in range(int(y.shape[0])):\n",
    "        labels.append([])\n",
    "        for j in range(len(y[i])):\n",
    "            if (y[i][j] != 0):\n",
    "                labels[i].append(class_names[j])\n",
    "\n",
    "    with open(os.path.join(log_dir, meta_file), \"w\") as f:\n",
    "        for label in labels:\n",
    "            f.write(\"{}\\n\".format(label))\n",
    "\n",
    "    if feature_vector.ndim != 2:\n",
    "        print(\n",
    "            \"NOTE: Feature vector is not of form (BATCH, FEATURES)\"\n",
    "            \" reshaping to try and get it to this form!\"\n",
    "        )\n",
    "        feature_vector = tf.reshape(feature_vector, [feature_vector.shape[0], -1])\n",
    "    print(feature_vector.shape)\n",
    "\n",
    "    feature_vector = tf.Variable(feature_vector)\n",
    "    checkpoint = tf.train.Checkpoint(embedding=feature_vector)\n",
    "    checkpoint.save(os.path.join(log_dir, \"embeddings.ckpt\"))\n",
    "\n",
    "    # Set up config\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "    embedding.metadata_path = meta_file\n",
    "    embedding.sprite.image_path = \"sprites.png\"\n",
    "    embedding.sprite.single_image_dim.extend((x.shape[1], x.shape[2]))\n",
    "    projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90837fb3-359c-4587-9715-daec3d9de720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sprite(data):\n",
    "    \"\"\"\n",
    "    Tile images into sprite image.\n",
    "    Add any necessary padding\n",
    "    \"\"\"\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[..., np.newaxis], (1, 1, 1, 3))\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0), (0, 0), (0, 0))\n",
    "    data = np.pad(data, padding, mode=\"constant\", constant_values=0)\n",
    "\n",
    "    # Tile images into sprite\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3, 4))\n",
    "\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c456e5eb-54fe-45db-a745-2a162ad561a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_to_projector(X, feature_vectors, y, ['Albert', 'Eline', 'Erik', 'Kevin', 'Marcel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6a89c-e6bc-4915-9d12-b4d357657cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}